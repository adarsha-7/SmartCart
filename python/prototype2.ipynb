{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): DistilBertSdpaAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import pandas as pd\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "import yake\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "embedding-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Text Embedding Function\n",
    "def embed_text(text_list):\n",
    "    inputs = tokenizer(text_list, padding=True, truncation=True, max_length=128, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        last_hidden = outputs.last_hidden_state\n",
    "        mask = inputs['attention_mask'].unsqueeze(-1).expand(last_hidden.size()).float()\n",
    "        summed = (last_hidden * mask).sum(dim=1)\n",
    "        counts = mask.sum(dim=1).clamp(min=1e-9)\n",
    "        mean_pooled = summed / counts\n",
    "    return mean_pooled.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load Dataset and Preprocess\n",
    "df = pd.read_csv('Amazon-Products.csv').dropna(subset=['name'])\n",
    "df['text_features'] = (\n",
    "    df['name'].fillna('') + ' ' +\n",
    "    df['main_category'].fillna('') + ' ' +\n",
    "    df['sub_category'].fillna('')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-precomputed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 551585/551585 samples\n",
      "All embeddings computed.\n"
     ]
    }
   ],
   "source": [
    "# # Cell 4: Compute embeddings in batches\n",
    "# batch_size = 256\n",
    "# all_embeddings = []\n",
    "# for i in range(0, len(df), batch_size):\n",
    "#     batch_texts = df['text_features'].iloc[i:i+batch_size].tolist()\n",
    "#     batch_embeds = embed_text(batch_texts)\n",
    "#     all_embeddings.append(batch_embeds)\n",
    "#     print(f\"Processed {min(i+batch_size, len(df))}/{len(df)} samples\", end='\\r')\n",
    "# embeddings = torch.cat(all_embeddings)\n",
    "# print(\"\\nAll embeddings computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54662d40-3449-4c91-bd5d-00e460646741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0:\n",
      "  Match idx: 0, Score: 1.0000\n",
      "  Match idx: 243792, Score: 0.9947\n",
      "  Match idx: 69, Score: 0.9945\n",
      "  Match idx: 59, Score: 0.9942\n",
      "  Match idx: 6, Score: 0.9941\n",
      "Query 1:\n",
      "  Match idx: 233, Score: 1.0000\n",
      "  Match idx: 1, Score: 1.0000\n",
      "  Match idx: 3, Score: 0.9996\n",
      "  Match idx: 22, Score: 0.9996\n",
      "  Match idx: 35, Score: 0.9970\n",
      "Query 2:\n",
      "  Match idx: 2, Score: 1.0000\n",
      "  Match idx: 274, Score: 0.9990\n",
      "  Match idx: 22, Score: 0.9965\n",
      "  Match idx: 3, Score: 0.9962\n",
      "  Match idx: 233, Score: 0.9959\n",
      "Query 3:\n",
      "  Match idx: 3, Score: 1.0000\n",
      "  Match idx: 22, Score: 0.9997\n",
      "  Match idx: 233, Score: 0.9996\n",
      "  Match idx: 1, Score: 0.9996\n",
      "  Match idx: 35, Score: 0.9976\n",
      "Query 4:\n",
      "  Match idx: 4, Score: 1.0000\n",
      "  Match idx: 243804, Score: 0.9931\n",
      "  Match idx: 824, Score: 0.9929\n",
      "  Match idx: 339950, Score: 0.9908\n",
      "  Match idx: 585, Score: 0.9771\n",
      "Query 5:\n",
      "  Match idx: 5, Score: 1.0000\n",
      "  Match idx: 243812, Score: 0.9938\n",
      "  Match idx: 862, Score: 0.9935\n",
      "  Match idx: 339980, Score: 0.9911\n",
      "  Match idx: 23449, Score: 0.9861\n",
      "Query 6:\n",
      "  Match idx: 6, Score: 1.0000\n",
      "  Match idx: 16, Score: 0.9994\n",
      "  Match idx: 69, Score: 0.9985\n",
      "  Match idx: 59, Score: 0.9982\n",
      "  Match idx: 7, Score: 0.9981\n",
      "Query 7:\n",
      "  Match idx: 7, Score: 1.0000\n",
      "  Match idx: 16, Score: 0.9991\n",
      "  Match idx: 6, Score: 0.9981\n",
      "  Match idx: 59, Score: 0.9977\n",
      "  Match idx: 69, Score: 0.9964\n",
      "Query 8:\n",
      "  Match idx: 8, Score: 1.0000\n",
      "  Match idx: 51, Score: 0.9996\n",
      "  Match idx: 45, Score: 0.9989\n",
      "  Match idx: 13, Score: 0.9958\n",
      "  Match idx: 956, Score: 0.9934\n",
      "Query 9:\n",
      "  Match idx: 9, Score: 1.0000\n",
      "  Match idx: 168, Score: 0.9969\n",
      "  Match idx: 71, Score: 0.9949\n",
      "  Match idx: 243830, Score: 0.9946\n",
      "  Match idx: 957, Score: 0.9944\n"
     ]
    }
   ],
   "source": [
    "## Cell 4: Load precomputed FAISS index and embeddings or save them\n",
    "## LOAD\n",
    "# Load embeddings from .npy (assumes they were saved with float32 type)\n",
    "emb_np = np.load(\"all_embeddings.npy\")\n",
    "embeddings = torch.from_numpy(emb_np)\n",
    "# Load FAISS index\n",
    "index = faiss.read_index(\"faiss_cosine.index\")\n",
    "print(\"✅ Loaded precomputed embeddings and FAISS index.\")\n",
    "\n",
    "## SAVE\n",
    "# # Convert to numpy and normalize (L2 norm for cosine similarity)\n",
    "# emb_np = embeddings.cpu().numpy().astype('float32')\n",
    "# faiss.normalize_L2(emb_np)  # In-place normalization\n",
    "# # Using inner product after L2 norm → equivalent to cosine similarity\n",
    "# index = faiss.IndexFlatIP(emb_np.shape[1])\n",
    "# index.add(emb_np)  # Add all vectors\n",
    "# top_k = 5\n",
    "# D, I = index.search(emb_np[:10], top_k)  # D = scores, I = indices\n",
    "# for i, (scores, indices) in enumerate(zip(D, I)):\n",
    "#     print(f\"Query {i}:\")\n",
    "#     for score, idx in zip(scores, indices):\n",
    "#         print(f\"  Match idx: {idx}, Score: {score:.4f}\")\n",
    "# np.save(\"all_embeddings.npy\", emb_np)\n",
    "# faiss.write_index(index, \"faiss_cosine.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "category-filtering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Keyword extraction and category filtering\n",
    "kw_extractor = yake.KeywordExtractor(top=5)\n",
    "\n",
    "def extract_keywords_yake(text, max_keywords=5):\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    return [kw for kw, score in keywords[:max_keywords]]\n",
    "\n",
    "def filter_df_by_query_categories(df, query):\n",
    "    keywords = extract_keywords_yake(query)\n",
    "    keywords = [kw.lower() for kw in keywords]\n",
    "    available_cats = df['main_category'].fillna('').str.lower().unique()\n",
    "    selected_cats = [cat for cat in available_cats if any(kw in cat for kw in keywords)]\n",
    "    if not selected_cats:\n",
    "        selected_cats = available_cats\n",
    "    filtered_df = df[df['main_category'].fillna('').str.lower().isin(selected_cats)]\n",
    "    print(f\"Filtered to categories: {selected_cats}\")\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, HTML\n",
    "\n",
    "# Display image from URL\n",
    "def display_image(url, width=200):\n",
    "    if isinstance(url, str) and url.startswith(\"http\"):\n",
    "        display(HTML(f'<img src=\"{url}\" width=\"{width}\"/>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "search-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this function to your notebook (new cell)\n",
    "\n",
    "def filter_df_by_query_categories(df, query, top_k=5):\n",
    "    keywords = extract_keywords_yake(query, max_keywords=5)\n",
    "    keywords = [kw.lower() for kw in keywords]\n",
    "    \n",
    "    # Get available categories in lower-case\n",
    "    available_cats = df['main_category'].fillna('').str.lower().unique()\n",
    "    \n",
    "    # Find categories that contain any keyword\n",
    "    selected_cats = [cat for cat in available_cats if any(kw in cat for kw in keywords)]\n",
    "    if not selected_cats:\n",
    "        selected_cats = available_cats  # fallback to all\n",
    "    \n",
    "    # Filter df by selected categories\n",
    "    filtered_df = df[df['main_category'].fillna('').str.lower().isin(selected_cats)]\n",
    "    \n",
    "    print(f\"Filtered to categories: {selected_cats}\")\n",
    "    return filtered_df\n",
    "\n",
    "# Modify your search function to use this filter:\n",
    "def user_search_and_recommend_with_filter(df, model, tokenizer, embeddings, top_k=5, threshold=0.7):\n",
    "    while True:\n",
    "        query = input(\"Enter product description to search: \").strip()\n",
    "        if not query:\n",
    "            print(\"Please enter something!\")\n",
    "            continue\n",
    "        \n",
    "        filtered_df = filter_df_by_query_categories(df, query)\n",
    "        if filtered_df.empty:\n",
    "            print(\"No matching categories found. Searching entire dataset.\")\n",
    "            filtered_df = df\n",
    "        \n",
    "        # Get indices of filtered products to slice embeddings and index search accordingly\n",
    "        indices = filtered_df.index.to_list()\n",
    "        filtered_embs = embeddings[indices].numpy().astype('float32')\n",
    "        faiss.normalize_L2(filtered_embs)\n",
    "        \n",
    "        # Build temporary FAISS index on filtered embeddings\n",
    "        tmp_index = faiss.IndexFlatIP(filtered_embs.shape[1])\n",
    "        tmp_index.add(filtered_embs)\n",
    "        \n",
    "        query_emb = embed_text([query]).cpu().numpy().astype('float32')\n",
    "        faiss.normalize_L2(query_emb)\n",
    "        \n",
    "        D, I = tmp_index.search(query_emb, top_k)\n",
    "        filtered_results = [(score, indices[idx]) for score, idx in zip(D[0], I[0]) if score >= threshold]\n",
    "        \n",
    "        if not filtered_results:\n",
    "            print(f\"No products found with similarity above {threshold}. Please try again.\\n\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nTop {len(filtered_results)} results for your query '{query}':\\n\")\n",
    "        for score, idx in filtered_results:\n",
    "            product = df.loc[idx]\n",
    "            print(f\"Score: {score:.4f}\")\n",
    "            print(f\"Product Name: {product['name']}\")\n",
    "            print(f\"Category: {product['main_category']} / {product['sub_category']}\")\n",
    "            print(f\"Price: {product.get('discount_price', 'N/A')} (Original: {product.get('actual_price', 'N/A')})\")\n",
    "            print(f\"Ratings: {product.get('ratings', 'N/A')} from {product.get('no_of_ratings', 'N/A')} users\")\n",
    "            print(f\"Link: {product.get('link', 'N/A')}\")\n",
    "            display_image(product.get('image'))\n",
    "            print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Run the search function\n",
    "user_search_and_recommend_with_filter(df, model, tokenizer, embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
